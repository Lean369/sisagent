# Sistema de M√©tricas con PostgreSQL (Implementaci√≥n lista para usar)

import psycopg2
from psycopg2 import sql
from psycopg2.extras import execute_batch
from psycopg2 import pool
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
import os
from threading import Lock
import time
import logging

# Usar el logger principal configurado en agent.py
logger = logging.getLogger(os.getenv('LOGGER_NAME', 'agent'))

# Configuraci√≥n de PostgresSQL
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'database': os.getenv('DB_NAME_METRICS', 'metrics_db'),
    'user': os.getenv('DB_USER', 'sisbot_user'),
    'password': os.getenv('DB_PASSWORD', 'postgres_password'),
    'port': os.getenv('DB_PORT', '5432')
}

# Pool de conexiones (inicializaci√≥n lazy para evitar errores al importar)
connection_pool = None

def _get_connection_pool():
    """Obtiene o crea el pool de conexiones (lazy initialization)"""
    global connection_pool
    if connection_pool is None:
        try:
            connection_pool = psycopg2.pool.ThreadedConnectionPool(
                minconn=1,
                maxconn=10,
                **DB_CONFIG
            )
            logger.info("‚úÖ Pool de conexiones PostgreSQL inicializado")
        except Exception as e:
            msg = str(e).lower()
            logger.error(f"‚ùå Error conectando a PostgreSQL: {e}")
            # Si la causa es que la base de datos no existe, intentar crearla
            if 'does not exist' in msg or 'database "' in msg and 'does not exist' in msg:
                dbname = DB_CONFIG.get('database')
                logger.warning(f"üõ†Ô∏è  Intentando crear la base de datos '{dbname}' porque no existe")
                try:
                    # Intentar conectar a la base 'postgres' para crear la base objetivo
                    tmp_conf = DB_CONFIG.copy()
                    tmp_conf['database'] = 'postgres'
                    conn = psycopg2.connect(**tmp_conf)
                    conn.autocommit = True
                    cur = conn.cursor()
                    # Verificar existencia por si otro proceso la cre√≥
                    cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (dbname,))
                    if cur.fetchone() is None:
                        cur.execute(sql.SQL("CREATE DATABASE {} OWNER {};").format(
                            sql.Identifier(dbname), sql.Identifier(DB_CONFIG.get('user'))
                        ))
                        logger.info(f"‚úÖ Base de datos '{dbname}' creada correctamente")
                    cur.close()
                    conn.close()
                    # Reintentar crear el pool
                    connection_pool = psycopg2.pool.ThreadedConnectionPool(
                        minconn=1,
                        maxconn=10,
                        **DB_CONFIG
                    )
                    logger.info("‚úÖ Pool de conexiones PostgreSQL inicializado tras crear la DB")
                except Exception as e2:
                    logger.error(f"‚ùå No fue posible crear la base de datos '{dbname}': {e2}")
                    raise
            else:
                raise
    return connection_pool

@dataclass
class MetricaMensaje:
    timestamp: float
    user_id: str
    tiempo_procesamiento: float
    tokens_usados: int
    fue_cache: bool
    error: bool
    mensaje_length: int = 0
    intencion: Optional[str] = None

class SistemaMetricasDB:
    """Sistema de m√©tricas con persistencia en PostgreSQL"""
    
    def __init__(self):
        self.buffer: List[MetricaMensaje] = []
        # Buffer size configurable via env var for testing/production
        try:
            self.buffer_size = int(os.getenv('METRICS_BUFFER_SIZE', '1'))  # default=1 for immediate inserts
        except Exception:
            self.buffer_size = 1
        self.lock = Lock()
        self._crear_tablas()
    
    def _get_connection(self):
        """Obtiene conexi√≥n del pool"""
        pool = _get_connection_pool()
        return pool.getconn()
    
    def _return_connection(self, conn):
        """Devuelve conexi√≥n al pool"""
        pool = _get_connection_pool()
        pool.putconn(conn)
    
    def _crear_tablas(self):
        """Crea tablas necesarias si no existen"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            # Tabla principal de m√©tricas
            cur.execute("""
                CREATE TABLE IF NOT EXISTS metricas_mensajes (
                    id SERIAL PRIMARY KEY,
                    timestamp TIMESTAMP NOT NULL,
                    user_id VARCHAR(100) NOT NULL,
                    tiempo_procesamiento REAL NOT NULL,
                    tokens_usados INTEGER DEFAULT 0,
                    fue_cache BOOLEAN DEFAULT FALSE,
                    error BOOLEAN DEFAULT FALSE,
                    mensaje_length INTEGER DEFAULT 0,
                    intencion VARCHAR(50),
                    created_at TIMESTAMP DEFAULT NOW()
                );
                
                CREATE INDEX IF NOT EXISTS idx_metricas_timestamp 
                ON metricas_mensajes(timestamp);
                
                CREATE INDEX IF NOT EXISTS idx_metricas_user_id 
                ON metricas_mensajes(user_id);
                
                CREATE INDEX IF NOT EXISTS idx_metricas_error 
                ON metricas_mensajes(error);
            """)
            
            # Tabla de m√©tricas agregadas por hora
            cur.execute("""
                CREATE TABLE IF NOT EXISTS metricas_hora (
                    id SERIAL PRIMARY KEY,
                    hora TIMESTAMP NOT NULL,
                    total_mensajes INTEGER DEFAULT 0,
                    mensajes_exitosos INTEGER DEFAULT 0,
                    mensajes_error INTEGER DEFAULT 0,
                    mensajes_cache INTEGER DEFAULT 0,
                    tiempo_promedio REAL DEFAULT 0,
                    tokens_totales INTEGER DEFAULT 0,
                    usuarios_unicos INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT NOW(),
                    UNIQUE(hora)
                );
                
                CREATE INDEX IF NOT EXISTS idx_metricas_hora_hora 
                ON metricas_hora(hora);
            """)
            
            # Tabla de estad√≠sticas por usuario
            cur.execute("""
                CREATE TABLE IF NOT EXISTS metricas_usuarios (
                    id SERIAL PRIMARY KEY,
                    user_id VARCHAR(100) NOT NULL,
                    total_mensajes INTEGER DEFAULT 0,
                    ultimo_mensaje TIMESTAMP,
                    primer_mensaje TIMESTAMP,
                    tiempo_promedio REAL DEFAULT 0,
                    tasa_error REAL DEFAULT 0,
                    created_at TIMESTAMP DEFAULT NOW(),
                    updated_at TIMESTAMP DEFAULT NOW(),
                    UNIQUE(user_id)
                );
                
                CREATE INDEX IF NOT EXISTS idx_metricas_usuarios_user_id 
                ON metricas_usuarios(user_id);
            """)
            
            conn.commit()
            cur.close()
            logger.info("‚úÖ Tablas de m√©tricas creadas/verificadas")
            
        except Exception as e:
            logger.error(f"‚ùå Error creando tablas: {e}")
            conn.rollback()
        finally:
            self._return_connection(conn)
    
    def registrar_metrica(self, metrica: MetricaMensaje):
        """Registra una m√©trica (con buffering)"""
        with self.lock:
            self.buffer.append(metrica)
            try:
                logger.debug(f"üî∏ Buffer metrics: {len(self.buffer)}/{self.buffer_size}")
            except Exception:
                pass
            
            # Si buffer est√° lleno, guardar en DB
            if len(self.buffer) >= self.buffer_size:
                self._flush_buffer()
    
    def _flush_buffer(self):
        """Guarda buffer en base de datos"""
        if not self.buffer:
            return
        
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            # Preparar datos para batch insert
            datos = []
            for m in self.buffer:
                datos.append((
                    datetime.fromtimestamp(m.timestamp),
                    m.user_id,
                    m.tiempo_procesamiento,
                    m.tokens_usados,
                    m.fue_cache,
                    m.error,
                    m.mensaje_length,
                    m.intencion
                ))
            
            # Batch insert (mucho m√°s r√°pido)
            execute_batch(cur, """
                INSERT INTO metricas_mensajes 
                (timestamp, user_id, tiempo_procesamiento, tokens_usados, 
                 fue_cache, error, mensaje_length, intencion)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, datos)
            
            conn.commit()
            cur.close()
            
            # Actualizar m√©tricas agregadas
            self._actualizar_metricas_agregadas()
            
            # Limpiar buffer
            self.buffer.clear()
            
            logger.info(f"üíæ Guardadas {len(datos)} m√©tricas en DB")
            return len(datos)
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando m√©tricas: {e}")
            conn.rollback()
        finally:
            self._return_connection(conn)

    def forzar_flush(self):
        """Forzar el vaciado del buffer de m√©tricas y retornar cu√°ntas m√©tricas se insertaron."""
        with self.lock:
            cantidad = len(self.buffer)
            try:
                inserted = self._flush_buffer() or 0
                return {"buffer_before": cantidad, "inserted": inserted}
            except Exception as e:
                print(f"‚ùå Error forzando flush: {e}")
                return {"error": str(e)}
    
    def _actualizar_metricas_agregadas(self):
        """Actualiza tablas de m√©tricas agregadas"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            # Actualizar m√©tricas por hora (√∫ltima hora)
            cur.execute("""
                INSERT INTO metricas_hora (
                    hora, total_mensajes, mensajes_exitosos, mensajes_error,
                    mensajes_cache, tiempo_promedio, tokens_totales, usuarios_unicos
                )
                SELECT 
                    DATE_TRUNC('hour', timestamp) as hora,
                    COUNT(*) as total,
                    COUNT(*) FILTER (WHERE NOT error) as exitosos,
                    COUNT(*) FILTER (WHERE error) as errores,
                    COUNT(*) FILTER (WHERE fue_cache) as cache,
                    AVG(tiempo_procesamiento) as tiempo_prom,
                    SUM(tokens_usados) as tokens_tot,
                    COUNT(DISTINCT user_id) as usuarios
                FROM metricas_mensajes
                WHERE timestamp >= NOW() - INTERVAL '1 hour'
                GROUP BY DATE_TRUNC('hour', timestamp)
                ON CONFLICT (hora) DO UPDATE SET
                    total_mensajes = EXCLUDED.total_mensajes,
                    mensajes_exitosos = EXCLUDED.mensajes_exitosos,
                    mensajes_error = EXCLUDED.mensajes_error,
                    mensajes_cache = EXCLUDED.mensajes_cache,
                    tiempo_promedio = EXCLUDED.tiempo_promedio,
                    tokens_totales = EXCLUDED.tokens_totales,
                    usuarios_unicos = EXCLUDED.usuarios_unicos;
            """)
            
            # Actualizar estad√≠sticas por usuario
            cur.execute("""
                INSERT INTO metricas_usuarios (
                    user_id, total_mensajes, ultimo_mensaje, primer_mensaje,
                    tiempo_promedio, tasa_error
                )
                SELECT 
                    user_id,
                    COUNT(*) as total,
                    MAX(timestamp) as ultimo,
                    MIN(timestamp) as primero,
                    AVG(tiempo_procesamiento) as tiempo_prom,
                    (COUNT(*) FILTER (WHERE error)::FLOAT / COUNT(*)) * 100 as tasa_err
                FROM metricas_mensajes
                WHERE timestamp >= NOW() - INTERVAL '24 hours'
                GROUP BY user_id
                ON CONFLICT (user_id) DO UPDATE SET
                    total_mensajes = EXCLUDED.total_mensajes,
                    ultimo_mensaje = EXCLUDED.ultimo_mensaje,
                    tiempo_promedio = EXCLUDED.tiempo_promedio,
                    tasa_error = EXCLUDED.tasa_error,
                    updated_at = NOW();
            """)
            
            conn.commit()
            cur.close()
            
        except Exception as e:
            logger.error(f"‚ùå Error actualizando agregados: {e}")
            conn.rollback()
        finally:
            self._return_connection(conn)
    
    def obtener_estadisticas_generales(self, horas: int = 24) -> Dict:
        """Obtiene estad√≠sticas generales del sistema"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            # Estad√≠sticas √∫ltimas N horas
            cur.execute("""
                SELECT 
                    COUNT(*) as total_mensajes,
                    COUNT(*) FILTER (WHERE NOT error) as exitosos,
                    COUNT(*) FILTER (WHERE error) as errores,
                    COUNT(*) FILTER (WHERE fue_cache) as cache,
                    AVG(tiempo_procesamiento) as tiempo_promedio,
                    MIN(tiempo_procesamiento) as tiempo_min,
                    MAX(tiempo_procesamiento) as tiempo_max,
                    SUM(tokens_usados) as tokens_totales,
                    COUNT(DISTINCT user_id) as usuarios_unicos
                FROM metricas_mensajes
                WHERE timestamp >= NOW() - INTERVAL '%s hours'
            """, (horas,))
            
            resultado = cur.fetchone()
            cur.close()
            
            if not resultado or resultado[0] == 0:
                return {"error": "Sin datos en el per√≠odo especificado"}
            
            total = resultado[0]
            exitosos = resultado[1] or 0
            errores = resultado[2] or 0
            cache = resultado[3] or 0
            
            return {
                "periodo_horas": horas,
                "total_mensajes": total,
                "mensajes_exitosos": exitosos,
                "mensajes_error": errores,
                "mensajes_cache": cache,
                "tasa_exito_porcentaje": round((exitosos / total) * 100, 2) if total > 0 else 0,
                "tasa_error_porcentaje": round((errores / total) * 100, 2) if total > 0 else 0,
                "tasa_cache_porcentaje": round((cache / total) * 100, 2) if total > 0 else 0,
                "tiempo_promedio_segundos": round(resultado[4] or 0, 2),
                "tiempo_minimo_segundos": round(resultado[5] or 0, 2),
                "tiempo_maximo_segundos": round(resultado[6] or 0, 2),
                "tokens_totales": resultado[7] or 0,
                "usuarios_unicos": resultado[8] or 0,
                "mensajes_por_usuario": round(total / (resultado[8] or 1), 2)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estad√≠sticas: {e}")
            return {"error": str(e)}
        finally:
            self._return_connection(conn)
    
    def obtener_metricas_por_hora(self, ultimas_horas: int = 24) -> List[Dict]:
        """Obtiene m√©tricas agregadas por hora"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            cur.execute("""
                SELECT 
                    hora,
                    total_mensajes,
                    mensajes_exitosos,
                    mensajes_error,
                    mensajes_cache,
                    tiempo_promedio,
                    tokens_totales,
                    usuarios_unicos
                FROM metricas_hora
                WHERE hora >= NOW() - INTERVAL '%s hours'
                ORDER BY hora DESC
            """, (ultimas_horas,))
            
            resultados = []
            for row in cur.fetchall():
                resultados.append({
                    "hora": row[0].isoformat(),
                    "total_mensajes": row[1],
                    "exitosos": row[2],
                    "errores": row[3],
                    "cache": row[4],
                    "tiempo_promedio": round(row[5], 2),
                    "tokens": row[6],
                    "usuarios": row[7]
                })
            
            cur.close()
            return resultados
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo m√©tricas por hora: {e}")
            return []
        finally:
            self._return_connection(conn)

    def obtener_metricas_por_hora_rango(self, start_iso: str, end_iso: str) -> List[Dict]:
        """Obtiene m√©tricas agregadas por hora en un rango de fechas (ISO strings)."""
        conn = self._get_connection()
        try:
            cur = conn.cursor()

            cur.execute("""
                SELECT 
                    hora,
                    total_mensajes,
                    mensajes_exitosos,
                    mensajes_error,
                    mensajes_cache,
                    tiempo_promedio,
                    tokens_totales,
                    usuarios_unicos
                FROM metricas_hora
                WHERE hora >= %s AND hora <= %s
                ORDER BY hora DESC
            """, (start_iso, end_iso))

            resultados = []
            for row in cur.fetchall():
                resultados.append({
                    "hora": row[0].isoformat(),
                    "total_mensajes": row[1],
                    "exitosos": row[2],
                    "errores": row[3],
                    "cache": row[4],
                    "tiempo_promedio": round(row[5], 2) if row[5] is not None else 0,
                    "tokens": row[6],
                    "usuarios": row[7]
                })

            cur.close()
            return resultados

        except Exception as e:
            logger.error(f"‚ùå Error obteniendo m√©tricas por hora (rango): {e}")
            return []
        finally:
            self._return_connection(conn)

    def obtener_estadisticas_por_rango(self, start_iso: str, end_iso: str) -> Dict:
        """Obtiene estad√≠sticas generales entre dos timestamps ISO."""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            cur.execute("""
                SELECT 
                    COUNT(*) as total_mensajes,
                    COUNT(*) FILTER (WHERE NOT error) as exitosos,
                    COUNT(*) FILTER (WHERE error) as errores,
                    COUNT(*) FILTER (WHERE fue_cache) as cache,
                    AVG(tiempo_procesamiento) as tiempo_promedio,
                    MIN(tiempo_procesamiento) as tiempo_min,
                    MAX(tiempo_procesamiento) as tiempo_max,
                    SUM(tokens_usados) as tokens_totales,
                    COUNT(DISTINCT user_id) as usuarios_unicos
                FROM metricas_mensajes
                WHERE timestamp >= %s AND timestamp <= %s
            """, (start_iso, end_iso))

            resultado = cur.fetchone()
            cur.close()

            if not resultado or resultado[0] == 0:
                return {"error": "Sin datos en el per√≠odo especificado"}

            total = resultado[0]
            exitosos = resultado[1] or 0
            errores = resultado[2] or 0
            cache = resultado[3] or 0

            return {
                "periodo_start": start_iso,
                "periodo_end": end_iso,
                "total_mensajes": total,
                "mensajes_exitosos": exitosos,
                "mensajes_error": errores,
                "mensajes_cache": cache,
                "tasa_exito_porcentaje": round((exitosos / total) * 100, 2) if total > 0 else 0,
                "tasa_error_porcentaje": round((errores / total) * 100, 2) if total > 0 else 0,
                "tasa_cache_porcentaje": round((cache / total) * 100, 2) if total > 0 else 0,
                "tiempo_promedio_segundos": round(resultado[4] or 0, 2),
                "tiempo_minimo_segundos": round(resultado[5] or 0, 2),
                "tiempo_maximo_segundos": round(resultado[6] or 0, 2),
                "tokens_totales": resultado[7] or 0,
                "usuarios_unicos": resultado[8] or 0,
                "mensajes_por_usuario": round(total / (resultado[8] or 1), 2)
            }

        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estad√≠sticas por rango: {e}")
            return {"error": str(e)}
        finally:
            self._return_connection(conn)
    
    def obtener_top_usuarios(self, limit: int = 10) -> List[Dict]:
        """Obtiene usuarios m√°s activos"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            cur.execute("""
                SELECT 
                    user_id,
                    total_mensajes,
                    ultimo_mensaje,
                    tiempo_promedio,
                    tasa_error
                FROM metricas_usuarios
                ORDER BY total_mensajes DESC
                LIMIT %s
            """, (limit,))
            
            resultados = []
            for row in cur.fetchall():
                resultados.append({
                    "user_id": row[0],
                    "total_mensajes": row[1],
                    "ultimo_mensaje": row[2].isoformat() if row[2] else None,
                    "tiempo_promedio": round(row[3], 2),
                    "tasa_error": round(row[4], 2)
                })
            
            cur.close()
            return resultados
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo top usuarios: {e}")
            return []
        finally:
            self._return_connection(conn)
    
    def limpiar_datos_antiguos(self, dias: int = 30):
        """Elimina m√©tricas detalladas antiguas (mantiene agregados)"""
        conn = self._get_connection()
        try:
            cur = conn.cursor()
            
            cur.execute("""
                DELETE FROM metricas_mensajes
                WHERE timestamp < NOW() - INTERVAL '%s days'
            """, (dias,))
            
            eliminados = cur.rowcount
            conn.commit()
            cur.close()
            
            logger.info(f"üßπ Eliminadas {eliminados} m√©tricas antiguas (>{dias} d√≠as)")
            return eliminados
            
        except Exception as e:
            logger.error(f"‚ùå Error limpiando datos: {e}")
            conn.rollback()
            return 0
        finally:
            self._return_connection(conn)

    def borrar_todas_metricas(self):
        """Borra todas las tablas de m√©tricas y reinicia los contadores.

        Devuelve un dict con los conteos eliminados por tabla antes del borrado.
        """
        conn = self._get_connection()
        try:
            cur = conn.cursor()

            # Contar filas actuales para reporte
            cur.execute("SELECT COUNT(*) FROM metricas_mensajes")
            c_mensajes = cur.fetchone()[0] or 0
            cur.execute("SELECT COUNT(*) FROM metricas_hora")
            c_hora = cur.fetchone()[0] or 0
            cur.execute("SELECT COUNT(*) FROM metricas_usuarios")
            c_usuarios = cur.fetchone()[0] or 0

            # Truncar las tablas y reiniciar identities
            cur.execute("TRUNCATE metricas_mensajes, metricas_hora, metricas_usuarios RESTART IDENTITY CASCADE;")
            conn.commit()
            cur.close()

            logger.info(f"üßπ Truncadas tablas de m√©tricas: mensajes={c_mensajes}, hora={c_hora}, usuarios={c_usuarios}")
            return {
                "metricas_mensajes": c_mensajes,
                "metricas_hora": c_hora,
                "metricas_usuarios": c_usuarios,
                "total": int(c_mensajes + c_hora + c_usuarios)
            }

        except Exception as e:
            logger.error(f"‚ùå Error borrando todas las m√©tricas: {e}")
            conn.rollback()
            return {"error": str(e)}
        finally:
            self._return_connection(conn)
    
    def __del__(self):
        """Asegura que el buffer se guarde al destruir el objeto"""
        self._flush_buffer()

# Instancia global
metricas_db = SistemaMetricasDB()

# Alias para compatibilidad
MetricsDB = SistemaMetricasDB